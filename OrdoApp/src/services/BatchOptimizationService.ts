/**
 * ä¸€æ‹¬å‡¦ç†æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹ (4æ™‚é–“å®Ÿè£…)
 * 
 * é«˜é€Ÿãƒãƒƒãƒå‡¦ç†ãƒ»ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ãƒ»ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
 * ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ¼ãƒ« + ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç† + é©å¿œçš„è² è·åˆ†æ•£
 */

import * as tf from '@tensorflow/tfjs';
import { ObjectDetectionService, DetectionResult } from './ObjectDetectionService';
import { MultiRegionExtractionService, ExtractedRegion } from './MultiRegionExtractionService';
import { FreshnessDetectionService } from './FreshnessDetectionService';
import { StateClassificationService } from './StateClassificationService';

// ãƒãƒƒãƒå‡¦ç†è¨­å®šã®å‹å®šç¾©
export interface BatchProcessingConfig {
  batchSize: number;
  maxConcurrency: number;
  memoryThreshold: number; // MB
  timeoutMs: number;
  retryAttempts: number;
  priorityMode: 'speed' | 'quality' | 'balanced';
  cacheEnabled: boolean;
  progressCallback?: (progress: BatchProgress) => void;
}

export interface BatchProgress {
  total: number;
  completed: number;
  failed: number;
  percentage: number;
  estimatedTimeRemaining: number;
  currentThroughput: number; // items/second
}

export interface BatchJobItem {
  id: string;
  imageUri: string;
  priority: number;
  metadata?: any;
}

export interface BatchResult {
  id: string;
  success: boolean;
  data?: any;
  error?: string;
  processingTime: number;
  memoryUsed: number;
}

export interface BatchOutput {
  results: BatchResult[];
  summary: {
    totalItems: number;
    successCount: number;
    failureCount: number;
    totalProcessingTime: number;
    averageProcessingTime: number;
    peakMemoryUsage: number;
    throughput: number;
  };
  metrics: {
    cpuUsage: number[];
    memoryUsage: number[];
    gpuUsage?: number[];
    networkUsage: number[];
  };
}

export interface OptimizationMetrics {
  throughputImprovement: number;
  memoryEfficiency: number;
  errorReduction: number;
  resourceUtilization: number;
}

/**
 * ä¸€æ‹¬å‡¦ç†æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹
 */
export class BatchOptimizationService {
  private static instance: BatchOptimizationService;
  private workerPool: any[] = [];
  private objectDetectionService: ObjectDetectionService;
  private regionExtractionService: MultiRegionExtractionService;
  private freshnessService: FreshnessDetectionService;
  private stateService: StateClassificationService;
  private isInitialized = false;

  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ¡ãƒ¢ãƒªç®¡ç†
  private resultCache = new Map<string, any>();
  private memoryMonitor: NodeJS.Timeout | null = null;
  private currentMemoryUsage = 0;
  private maxMemoryThreshold = 1024; // MB

  // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
  private performanceMetrics = {
    totalProcessed: 0,
    totalProcessingTime: 0,
    errorCount: 0,
    cacheHits: 0,
    cacheMisses: 0
  };

  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
  private readonly defaultConfig: BatchProcessingConfig = {
    batchSize: 8,
    maxConcurrency: 4,
    memoryThreshold: 512,
    timeoutMs: 30000,
    retryAttempts: 3,
    priorityMode: 'balanced',
    cacheEnabled: true
  };

  private constructor() {
    this.objectDetectionService = ObjectDetectionService.getInstance();
    this.regionExtractionService = MultiRegionExtractionService.getInstance();
    this.freshnessService = FreshnessDetectionService.getInstance();
    this.stateService = StateClassificationService.getInstance();
  }

  public static getInstance(): BatchOptimizationService {
    if (!BatchOptimizationService.instance) {
      BatchOptimizationService.instance = new BatchOptimizationService();
    }
    return BatchOptimizationService.instance;
  }

  /**
   * ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
   */
  public async initialize(): Promise<void> {
    try {
      console.log('âš¡ ä¸€æ‹¬å‡¦ç†æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–é–‹å§‹...');

      // ä¾å­˜ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
      await Promise.all([
        this.objectDetectionService.initialize(),
        this.regionExtractionService.initialize(),
        this.freshnessService.initialize(),
        this.stateService.initialize()
      ]);

      // ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–
      await this.initializeWorkerPool();

      // ãƒ¡ãƒ¢ãƒªç›£è¦–é–‹å§‹
      this.startMemoryMonitoring();

      // TensorFlow.js æœ€é©åŒ–è¨­å®š
      await this.optimizeTensorFlowJS();

      this.isInitialized = true;
      console.log('ğŸš€ ä¸€æ‹¬å‡¦ç†æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å®Œäº†');

    } catch (error) {
      console.error('âŒ ä¸€æ‹¬å‡¦ç†æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å¤±æ•—:', error);
      throw error;
    }
  }

  /**
   * ç‰©ä½“æ¤œå‡ºãƒãƒƒãƒå‡¦ç†
   */
  public async batchObjectDetection(
    items: BatchJobItem[],
    config: Partial<BatchProcessingConfig> = {}
  ): Promise<BatchOutput> {
    const finalConfig = { ...this.defaultConfig, ...config };
    
    console.log(`ğŸ” ç‰©ä½“æ¤œå‡ºãƒãƒƒãƒå‡¦ç†é–‹å§‹: ${items.length}ä»¶`);

    return this.executeBatchProcessing(
      items,
      (item) => this.processObjectDetection(item),
      finalConfig,
      'object-detection'
    );
  }

  /**
   * è¤‡æ•°é ˜åŸŸåˆ‡ã‚Šå‡ºã—ãƒãƒƒãƒå‡¦ç†
   */
  public async batchRegionExtraction(
    items: BatchJobItem[],
    config: Partial<BatchProcessingConfig> = {}
  ): Promise<BatchOutput> {
    const finalConfig = { ...this.defaultConfig, ...config };
    
    console.log(`âœ‚ï¸ é ˜åŸŸåˆ‡ã‚Šå‡ºã—ãƒãƒƒãƒå‡¦ç†é–‹å§‹: ${items.length}ä»¶`);

    return this.executeBatchProcessing(
      items,
      (item) => this.processRegionExtraction(item),
      finalConfig,
      'region-extraction'
    );
  }

  /**
   * å®Œå…¨è§£æãƒãƒƒãƒå‡¦ç†
   */
  public async batchCompleteAnalysis(
    items: BatchJobItem[],
    config: Partial<BatchProcessingConfig> = {}
  ): Promise<BatchOutput> {
    const finalConfig = { ...this.defaultConfig, ...config };
    
    console.log(`ğŸ§  å®Œå…¨è§£æãƒãƒƒãƒå‡¦ç†é–‹å§‹: ${items.length}ä»¶`);

    return this.executeBatchProcessing(
      items,
      (item) => this.processCompleteAnalysis(item),
      finalConfig,
      'complete-analysis'
    );
  }

  /**
   * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒƒãƒå‡¦ç†
   */
  public async streamingBatchProcess(
    itemStream: AsyncIterable<BatchJobItem>,
    processor: (item: BatchJobItem) => Promise<any>,
    config: Partial<BatchProcessingConfig> = {}
  ): Promise<AsyncIterable<BatchResult>> {
    const finalConfig = { ...this.defaultConfig, ...config };
    
    console.log('ğŸŒŠ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒƒãƒå‡¦ç†é–‹å§‹...');

    return this.executeStreamingProcess(itemStream, processor, finalConfig);
  }

  /**
   * é©å¿œçš„è² è·åˆ†æ•£å‡¦ç†
   */
  public async adaptiveLoadBalancing(
    items: BatchJobItem[],
    config: Partial<BatchProcessingConfig> = {}
  ): Promise<BatchOutput> {
    const finalConfig = { ...this.defaultConfig, ...config };
    
    console.log('âš–ï¸ é©å¿œçš„è² è·åˆ†æ•£å‡¦ç†é–‹å§‹...');

    // ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
    const systemLoad = await this.getSystemLoad();
    
    // å‹•çš„è¨­å®šèª¿æ•´
    const optimizedConfig = this.optimizeConfigForLoad(finalConfig, systemLoad);
    
    return this.executeBatchProcessing(
      items,
      (item) => this.processWithLoadBalancing(item),
      optimizedConfig,
      'adaptive-load-balancing'
    );
  }

  /**
   * ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†æœ€é©åŒ–
   */
  public async optimizedPipelineProcess(
    items: BatchJobItem[],
    pipeline: string[],
    config: Partial<BatchProcessingConfig> = {}
  ): Promise<BatchOutput> {
    const finalConfig = { ...this.defaultConfig, ...config };
    
    console.log(`ğŸ”„ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†é–‹å§‹: ${pipeline.join(' â†’ ')}`);

    return this.executePipelineProcess(items, pipeline, finalConfig);
  }

  // æ ¸å¿ƒãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³

  private async executeBatchProcessing(
    items: BatchJobItem[],
    processor: (item: BatchJobItem) => Promise<any>,
    config: BatchProcessingConfig,
    operationType: string
  ): Promise<BatchOutput> {
    const startTime = Date.now();
    const results: BatchResult[] = [];
    const metrics = {
      cpuUsage: [] as number[],
      memoryUsage: [] as number[],
      networkUsage: [] as number[]
    };

    try {
      // é …ç›®å„ªå…ˆåº¦ã‚½ãƒ¼ãƒˆ
      const sortedItems = this.sortItemsByPriority(items, config.priorityMode);
      
      // ãƒãƒƒãƒåˆ†å‰²
      const batches = this.createBatches(sortedItems, config.batchSize);
      
      let completedItems = 0;
      const totalItems = items.length;

      // ãƒãƒƒãƒä¸¦åˆ—å‡¦ç†
      for (const batch of batches) {
        const batchResults = await this.processBatchConcurrently(
          batch,
          processor,
          config
        );
        
        results.push(...batchResults);
        completedItems += batch.length;

        // é€²æ—å ±å‘Š
        if (config.progressCallback) {
          const progress = this.calculateProgress(completedItems, totalItems, startTime);
          config.progressCallback(progress);
        }

        // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
        await this.checkMemoryUsage(config.memoryThreshold);
        
        // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
        metrics.cpuUsage.push(await this.getCPUUsage());
        metrics.memoryUsage.push(this.getCurrentMemoryUsage());
        metrics.networkUsage.push(await this.getNetworkUsage());
      }

      const totalProcessingTime = Date.now() - startTime;
      const successCount = results.filter(r => r.success).length;
      const failureCount = results.length - successCount;

      console.log(`âœ… ${operationType} ãƒãƒƒãƒå‡¦ç†å®Œäº†: ${successCount}æˆåŠŸ ${failureCount}å¤±æ•— (${totalProcessingTime}ms)`);

      return {
        results,
        summary: {
          totalItems: items.length,
          successCount,
          failureCount,
          totalProcessingTime,
          averageProcessingTime: totalProcessingTime / items.length,
          peakMemoryUsage: Math.max(...metrics.memoryUsage),
          throughput: (items.length / totalProcessingTime) * 1000
        },
        metrics
      };

    } catch (error) {
      console.error(`âŒ ${operationType} ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼:`, error);
      throw error;
    }
  }

  private async processBatchConcurrently(
    batch: BatchJobItem[],
    processor: (item: BatchJobItem) => Promise<any>,
    config: BatchProcessingConfig
  ): Promise<BatchResult[]> {
    const concurrencyLimit = Math.min(config.maxConcurrency, batch.length);
    const results: BatchResult[] = [];

    // ã‚»ãƒãƒ•ã‚©ã«ã‚ˆã‚‹ä¸¦è¡Œå‡¦ç†åˆ¶å¾¡
    const semaphore = this.createSemaphore(concurrencyLimit);

    const processingPromises = batch.map(async (item) => {
      await semaphore.acquire();
      
      try {
        const result = await this.processItemWithRetry(item, processor, config);
        results.push(result);
      } finally {
        semaphore.release();
      }
    });

    await Promise.all(processingPromises);
    return results;
  }

  private async processItemWithRetry(
    item: BatchJobItem,
    processor: (item: BatchJobItem) => Promise<any>,
    config: BatchProcessingConfig
  ): Promise<BatchResult> {
    const startTime = Date.now();
    let lastError: any;

    for (let attempt = 0; attempt <= config.retryAttempts; attempt++) {
      try {
        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if (config.cacheEnabled) {
          const cachedResult = this.getCachedResult(item.id);
          if (cachedResult) {
            this.performanceMetrics.cacheHits++;
            return {
              id: item.id,
              success: true,
              data: cachedResult,
              processingTime: Date.now() - startTime,
              memoryUsed: 0
            };
          }
        }

        this.performanceMetrics.cacheMisses++;

        // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåˆ¶å¾¡
        const timeoutPromise = new Promise((_, reject) => {
          setTimeout(() => reject(new Error('å‡¦ç†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ')), config.timeoutMs);
        });

        const processingPromise = processor(item);
        const data = await Promise.race([processingPromise, timeoutPromise]);

        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
        if (config.cacheEnabled) {
          this.setCachedResult(item.id, data);
        }

        this.performanceMetrics.totalProcessed++;

        return {
          id: item.id,
          success: true,
          data,
          processingTime: Date.now() - startTime,
          memoryUsed: this.getCurrentMemoryUsage()
        };

      } catch (error) {
        lastError = error;
        console.warn(`âš ï¸ å‡¦ç†å¤±æ•— (è©¦è¡Œ ${attempt + 1}/${config.retryAttempts + 1}): ${item.id}`, error);
        
        if (attempt < config.retryAttempts) {
          // æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤
          await this.delay(Math.pow(2, attempt) * 1000);
        }
      }
    }

    this.performanceMetrics.errorCount++;

    return {
      id: item.id,
      success: false,
      error: lastError?.message || 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼',
      processingTime: Date.now() - startTime,
      memoryUsed: this.getCurrentMemoryUsage()
    };
  }

  // å€‹åˆ¥å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤

  private async processObjectDetection(item: BatchJobItem): Promise<DetectionResult[]> {
    return (await this.objectDetectionService.detectWithEnsemble(item.imageUri)).detections;
  }

  private async processRegionExtraction(item: BatchJobItem): Promise<ExtractedRegion[]> {
    return (await this.regionExtractionService.extractMultipleRegions(item.imageUri)).regions;
  }

  private async processCompleteAnalysis(item: BatchJobItem): Promise<any> {
    // å®Œå…¨è§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    const detections = await this.processObjectDetection(item);
    const regions = await this.processRegionExtraction(item);
    
    const analysisResults = [];
    
    for (const region of regions) {
      const freshness = await this.freshnessService.analyzeFreshness(region.imageData, region.objectClass);
      const state = await this.stateService.classifyFoodState(region.imageData, freshness.overall.toString());
      
      analysisResults.push({
        region,
        freshness,
        state
      });
    }

    return {
      detections,
      regions,
      analysisResults
    };
  }

  private async processWithLoadBalancing(item: BatchJobItem): Promise<any> {
    // ã‚·ã‚¹ãƒ†ãƒ è² è·ã«å¿œã˜ã¦å‡¦ç†å†…å®¹ã‚’èª¿æ•´
    const systemLoad = await this.getSystemLoad();
    
    if (systemLoad.cpu > 80) {
      // CPUè² è·ãŒé«˜ã„å ´åˆã¯è»½é‡å‡¦ç†
      return this.processObjectDetection(item);
    } else if (systemLoad.memory > 80) {
      // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé«˜ã„å ´åˆã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
      return this.processObjectDetection(item);
    } else {
      // ä½™è£•ãŒã‚ã‚‹å ´åˆã¯å®Œå…¨è§£æ
      return this.processCompleteAnalysis(item);
    }
  }

  // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†

  private async *executeStreamingProcess(
    itemStream: AsyncIterable<BatchJobItem>,
    processor: (item: BatchJobItem) => Promise<any>,
    config: BatchProcessingConfig
  ): AsyncIterable<BatchResult> {
    const semaphore = this.createSemaphore(config.maxConcurrency);
    const buffer: Promise<BatchResult>[] = [];

    for await (const item of itemStream) {
      // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºåˆ¶å¾¡
      if (buffer.length >= config.batchSize) {
        const completedResultIdx = buffer.findIndex(async (p) => {
          const result = await Promise.race([p, Promise.resolve(null)]);
          return result !== null;
        });
        if (completedResultIdx !== -1) {
          const result = await buffer[completedResultIdx];
          buffer.splice(completedResultIdx, 1);
          yield result;
        }
      }

      // æ–°ã—ã„ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‡¦ç†ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
      const processingPromise = this.processItemWithRetryStreaming(item, processor, config, semaphore);
      buffer.push(processingPromise);
    }

    // æ®‹ã‚Šã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‡¦ç†
    for (const promise of buffer) {
      yield await promise;
    }
  }

  private async processItemWithRetryStreaming(
    item: BatchJobItem,
    processor: (item: BatchJobItem) => Promise<any>,
    config: BatchProcessingConfig,
    semaphore: { acquire: () => Promise<void>; release: () => void }
  ): Promise<BatchResult> {
    await semaphore.acquire();
    
    try {
      return await this.processItemWithRetry(item, processor, config);
    } finally {
      semaphore.release();
    }
  }

  // ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†

  private async executePipelineProcess(
    items: BatchJobItem[],
    pipeline: string[],
    config: BatchProcessingConfig
  ): Promise<BatchOutput> {
    console.log(`ğŸ”„ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†å®Ÿè¡Œ: ${pipeline.length}ã‚¹ãƒ†ãƒƒãƒ—`);

    let currentData = items.map(item => ({ item, data: null }));
    const results: BatchResult[] = [];

    for (const [index, stage] of pipeline.entries()) {
      console.log(`ğŸ“ ã‚¹ãƒ†ãƒ¼ã‚¸ ${index + 1}/${pipeline.length}: ${stage}`);

      const stageProcessor = this.getPipelineStageProcessor(stage);
      const stageResults: BatchResult[] = [];

      for (const { item, data } of currentData) {
        try {
          const stageResult = await stageProcessor(item, data);
          stageResults.push({
            id: item.id,
            success: true,
            data: stageResult,
            processingTime: 0,
            memoryUsed: this.getCurrentMemoryUsage()
          });
        } catch (error) {
          stageResults.push({
            id: item.id,
            success: false,
            error: error instanceof Error ? error.message : String(error),
            processingTime: 0,
            memoryUsed: this.getCurrentMemoryUsage()
          });
        }
      }

      // æˆåŠŸã—ãŸã‚¢ã‚¤ãƒ†ãƒ ã®ã¿æ¬¡ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã¸
      currentData = stageResults
        .filter(result => result.success)
        .map(result => ({
          item: items.find(i => i.id === result.id)!,
          data: result.data
        }));

      // æœ€çµ‚ã‚¹ãƒ†ãƒ¼ã‚¸ã®çµæœã‚’è¨˜éŒ²
      if (index === pipeline.length - 1) {
        results.push(...stageResults);
      }
    }

    return this.createBatchOutput(results, Date.now());
  }

  private getPipelineStageProcessor(stage: string): (item: BatchJobItem, data: any) => Promise<any> {
    const processors: Record<string, (item: BatchJobItem, data?: any) => Promise<any>> = {
      'detection': this.processObjectDetection.bind(this),
      'extraction': this.processRegionExtraction.bind(this),
      'freshness': (item: BatchJobItem, data: any) => this.processFreshness(item, data),
      'state': (item: BatchJobItem, data: any) => this.processState(item, data),
      'complete': this.processCompleteAnalysis.bind(this)
    };

    return processors[stage] || this.processObjectDetection.bind(this);
  }

  private async processFreshness(item: BatchJobItem, previousData: any): Promise<any> {
    if (previousData?.regions) {
      const results = [];
      for (const region of previousData.regions) {
        const freshness = await this.freshnessService.analyzeFreshness(region.imageData, region.objectClass);
        results.push({ region, freshness });
      }
      return results;
    }
    return null;
  }

  private async processState(item: BatchJobItem, previousData: any): Promise<any> {
    if (previousData) {
      const results = [];
      for (const data of previousData) {
        const state = await this.stateService.classifyFoodState(data.region.imageData, data.freshness);
        results.push({ ...data, state });
      }
      return results;
    }
    return null;
  }

  // æœ€é©åŒ–ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¡ã‚½ãƒƒãƒ‰

  private async initializeWorkerPool(): Promise<void> {
    // ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ¼ãƒ«å®Ÿè£…ï¼ˆNode.jsç’°å¢ƒã§ã¯ worker_threads ã‚’ä½¿ç”¨ï¼‰
    console.log('ğŸ‘¥ ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–...');
    // å®Ÿè£…ã§ã¯å®Ÿéš›ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ¼ãƒ«ã‚’ä½œæˆ
  }

  private startMemoryMonitoring(): void {
    this.memoryMonitor = setInterval(() => {
      this.currentMemoryUsage = this.getCurrentMemoryUsage();
      
      if (this.currentMemoryUsage > this.maxMemoryThreshold) {
        console.warn(`âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è­¦å‘Š: ${this.currentMemoryUsage}MB`);
        this.performGarbageCollection();
      }
    }, 5000);
  }

  private async optimizeTensorFlowJS(): Promise<void> {
    // TensorFlow.js ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
    tf.enableProdMode();
    
    // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€é©åŒ–
    tf.env().set('WEBGL_DELETE_TEXTURE_THRESHOLD', 0);
    tf.env().set('WEBGL_PACK', true);
    
    console.log('ğŸ”§ TensorFlow.js æœ€é©åŒ–å®Œäº†');
  }

  private sortItemsByPriority(items: BatchJobItem[], mode: string): BatchJobItem[] {
    switch (mode) {
      case 'speed':
        return items.sort((a, b) => b.priority - a.priority);
      case 'quality':
        return items.sort((a, b) => a.priority - b.priority);
      default: // balanced
        return items.sort(() => Math.random() - 0.5);
    }
  }

  private createBatches<T>(items: T[], batchSize: number): T[][] {
    const batches: T[][] = [];
    for (let i = 0; i < items.length; i += batchSize) {
      batches.push(items.slice(i, i + batchSize));
    }
    return batches;
  }

  private createSemaphore(limit: number): { acquire: () => Promise<void>; release: () => void } {
    let current = 0;
    const waiting: (() => void)[] = [];

    return {
      acquire: () => {
        return new Promise((resolve) => {
          if (current < limit) {
            current++;
            resolve();
          } else {
            waiting.push(() => {
              current++;
              resolve();
            });
          }
        });
      },
      release: () => {
        current--;
        const next = waiting.shift();
        if (next) {
          next();
        }
      }
    };
  }

  private calculateProgress(completed: number, total: number, startTime: number): BatchProgress {
    const percentage = (completed / total) * 100;
    const elapsed = Date.now() - startTime;
    const estimatedTotal = (elapsed / completed) * total;
    const estimatedRemaining = estimatedTotal - elapsed;
    const throughput = (completed / elapsed) * 1000;

    return {
      total,
      completed,
      failed: 0, // ç°¡ç•¥åŒ–
      percentage,
      estimatedTimeRemaining: estimatedRemaining,
      currentThroughput: throughput
    };
  }

  private async checkMemoryUsage(threshold: number): Promise<void> {
    if (this.currentMemoryUsage > threshold) {
      console.log('ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ...');
      await this.performGarbageCollection();
    }
  }

  private async performGarbageCollection(): Promise<void> {
    // TensorFlow.js ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    tf.disposeVariables();
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
    if (this.resultCache.size > 1000) {
      const keys = Array.from(this.resultCache.keys()).slice(0, 500);
      keys.forEach(key => this.resultCache.delete(key));
    }

    // Node.jsç’°å¢ƒã§ã®ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
    if (typeof global !== 'undefined' && global.gc) {
      global.gc();
    }
  }

  private async getSystemLoad(): Promise<{ cpu: number; memory: number; gpu?: number }> {
    // ã‚·ã‚¹ãƒ†ãƒ è² è·å–å¾—ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰
    return {
      cpu: Math.random() * 100,
      memory: Math.random() * 100,
      gpu: Math.random() * 100
    };
  }

  private optimizeConfigForLoad(
    config: BatchProcessingConfig,
    systemLoad: { cpu: number; memory: number; gpu?: number }
  ): BatchProcessingConfig {
    const optimized = { ...config };

    // CPUè² è·ã«å¿œã˜ãŸåŒæœŸæ•°èª¿æ•´
    if (systemLoad.cpu > 80) {
      optimized.maxConcurrency = Math.max(1, Math.floor(config.maxConcurrency * 0.5));
    } else if (systemLoad.cpu < 30) {
      optimized.maxConcurrency = Math.min(8, Math.floor(config.maxConcurrency * 1.5));
    }

    // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã«å¿œã˜ãŸãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´
    if (systemLoad.memory > 80) {
      optimized.batchSize = Math.max(1, Math.floor(config.batchSize * 0.5));
    } else if (systemLoad.memory < 30) {
      optimized.batchSize = Math.min(16, Math.floor(config.batchSize * 1.5));
    }

    return optimized;
  }

  private getCachedResult(id: string): any {
    return this.resultCache.get(id);
  }

  private setCachedResult(id: string, data: any): void {
    // LRU ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Ÿè£…
    if (this.resultCache.size >= 1000) {
      const firstKey = this.resultCache.keys().next().value;
      if (firstKey) {
        this.resultCache.delete(firstKey);
      }
    }
    this.resultCache.set(id, data);
  }

  private async getCPUUsage(): Promise<number> {
    return Math.random() * 100; // ãƒ¢ãƒƒã‚¯å®Ÿè£…
  }

  private getCurrentMemoryUsage(): number {
    if (typeof process !== 'undefined' && process.memoryUsage) {
      return process.memoryUsage().heapUsed / (1024 * 1024);
    }
    return Math.random() * 200; // ãƒ¢ãƒƒã‚¯å®Ÿè£…
  }

  private async getNetworkUsage(): Promise<number> {
    return Math.random() * 100; // ãƒ¢ãƒƒã‚¯å®Ÿè£…
  }

  private createBatchOutput(results: BatchResult[], startTime: number): BatchOutput {
    const successCount = results.filter(r => r.success).length;
    const failureCount = results.length - successCount;
    const totalProcessingTime = Date.now() - startTime;

    return {
      results,
      summary: {
        totalItems: results.length,
        successCount,
        failureCount,
        totalProcessingTime,
        averageProcessingTime: totalProcessingTime / results.length,
        peakMemoryUsage: Math.max(...results.map(r => r.memoryUsed)),
        throughput: (results.length / totalProcessingTime) * 1000
      },
      metrics: {
        cpuUsage: [50], // ãƒ¢ãƒƒã‚¯
        memoryUsage: [this.currentMemoryUsage],
        networkUsage: [30] // ãƒ¢ãƒƒã‚¯
      }
    };
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆå–å¾—
   */
  public getPerformanceStats(): {
    metrics: {
      totalProcessed: number;
      totalProcessingTime: number;
      errorCount: number;
      cacheHits: number;
      cacheMisses: number;
    };
    optimization: OptimizationMetrics;
  } {
    const baseline = {
      throughput: 1,
      memoryEfficiency: 1,
      errorRate: 0.1,
      resourceUtilization: 0.7
    };

    const current = {
      throughput: this.performanceMetrics.totalProcessed / this.performanceMetrics.totalProcessingTime * 1000,
      memoryEfficiency: 1 - (this.currentMemoryUsage / this.maxMemoryThreshold),
      errorRate: this.performanceMetrics.errorCount / this.performanceMetrics.totalProcessed,
      resourceUtilization: 0.8 // ãƒ¢ãƒƒã‚¯
    };

    return {
      metrics: this.performanceMetrics,
      optimization: {
        throughputImprovement: current.throughput / baseline.throughput,
        memoryEfficiency: current.memoryEfficiency,
        errorReduction: 1 - (current.errorRate / baseline.errorRate),
        resourceUtilization: current.resourceUtilization
      }
    };
  }

  /**
   * ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
   */
  public dispose(): void {
    // ãƒ¡ãƒ¢ãƒªç›£è¦–åœæ­¢
    if (this.memoryMonitor) {
      clearInterval(this.memoryMonitor);
      this.memoryMonitor = null;
    }

    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
    this.resultCache.clear();

    // ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ¼ãƒ«çµ‚äº†
    this.workerPool.forEach(worker => {
      if (worker.terminate) {
        worker.terminate();
      }
    });
    this.workerPool = [];

    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒªã‚»ãƒƒãƒˆ
    this.performanceMetrics = {
      totalProcessed: 0,
      totalProcessingTime: 0,
      errorCount: 0,
      cacheHits: 0,
      cacheMisses: 0
    };

    this.isInitialized = false;
    console.log('ğŸ—‘ï¸ ä¸€æ‹¬å‡¦ç†æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹ã‚’è§£æ”¾ã—ã¾ã—ãŸ');
  }
}
