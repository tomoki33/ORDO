/**
 * è¤‡æ•°é ˜åŸŸåˆ‡ã‚Šå‡ºã—ã‚µãƒ¼ãƒ“ã‚¹ (4æ™‚é–“å®Ÿè£…)
 * 
 * é«˜ç²¾åº¦ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ãƒãƒ«ãƒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆé ˜åŸŸæŠ½å‡ºãƒ»è‡ªå‹•ãƒˆãƒªãƒŸãƒ³ã‚°
 * ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ + ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµ±åˆ
 */

import * as tf from '@tensorflow/tfjs';
import { DetectionResult, ObjectDetectionService } from './ObjectDetectionService';

// é ˜åŸŸåˆ‡ã‚Šå‡ºã—çµæœã®å‹å®šç¾©
export interface SegmentationMask {
  mask: number[][]; // 2Dãƒã‚¹ã‚¯é…åˆ—
  boundingBox: {
    x: number;
    y: number;
    width: number;
    height: number;
  };
  area: number;
  confidence: number;
}

export interface ExtractedRegion {
  id: string;
  imageData: string; // Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
  originalBbox: {
    x: number;
    y: number;
    width: number;
    height: number;
  };
  croppedSize: {
    width: number;
    height: number;
  };
  segmentationMask: SegmentationMask;
  objectClass: string;
  confidence: number;
  extractionMetadata: {
    algorithm: string;
    processingTime: number;
    qualityScore: number;
    timestamp: Date;
  };
}

export interface MultiRegionOutput {
  regions: ExtractedRegion[];
  totalRegions: number;
  originalImageSize: { width: number; height: number };
  processingMetrics: {
    totalProcessingTime: number;
    averageQualityScore: number;
    successfulExtractions: number;
    failedExtractions: number;
  };
  metadata: {
    algorithm: string;
    version: string;
    timestamp: Date;
  };
}

export interface RegionExtractionConfig {
  minRegionSize: number;
  maxRegions: number;
  qualityThreshold: number;
  paddingRatio: number;
  outputSize?: { width: number; height: number };
  preserveAspectRatio: boolean;
  backgroundRemoval: boolean;
  edgeSmoothing: boolean;
}

/**
 * è¤‡æ•°é ˜åŸŸåˆ‡ã‚Šå‡ºã—ã‚µãƒ¼ãƒ“ã‚¹
 */
export class MultiRegionExtractionService {
  private static instance: MultiRegionExtractionService;
  private segmentationModels: Map<string, tf.LayersModel | tf.GraphModel> = new Map();
  private objectDetectionService: ObjectDetectionService;
  private isInitialized = false;

  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
  private readonly defaultConfig: RegionExtractionConfig = {
    minRegionSize: 50,
    maxRegions: 10,
    qualityThreshold: 0.7,
    paddingRatio: 0.1,
    outputSize: { width: 224, height: 224 },
    preserveAspectRatio: true,
    backgroundRemoval: true,
    edgeSmoothing: true
  };

  private constructor() {
    this.objectDetectionService = ObjectDetectionService.getInstance();
  }

  public static getInstance(): MultiRegionExtractionService {
    if (!MultiRegionExtractionService.instance) {
      MultiRegionExtractionService.instance = new MultiRegionExtractionService();
    }
    return MultiRegionExtractionService.instance;
  }

  /**
   * ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
   */
  public async initialize(): Promise<void> {
    try {
      console.log('ğŸ¯ è¤‡æ•°é ˜åŸŸåˆ‡ã‚Šå‡ºã—ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–é–‹å§‹...');

      // ä¾å­˜ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
      await this.objectDetectionService.initialize();

      // ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
      await Promise.all([
        this.loadDeepLabModel(),
        this.loadMaskRCNNModel(),
        this.loadUNetModel()
      ]);

      this.isInitialized = true;
      console.log('ğŸš€ è¤‡æ•°é ˜åŸŸåˆ‡ã‚Šå‡ºã—ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å®Œäº†');

    } catch (error) {
      console.error('âŒ è¤‡æ•°é ˜åŸŸåˆ‡ã‚Šå‡ºã—ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å¤±æ•—:', error);
      throw error;
    }
  }

  /**
   * DeepLab v3+ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
   */
  private async loadDeepLabModel(): Promise<void> {
    try {
      console.log('ğŸ“¥ DeepLab v3+ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...');
      
      const model = await this.createDeepLabModel();
      this.segmentationModels.set('deeplab', model);
      
      console.log('âœ… DeepLab v3+ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†');
    } catch (error) {
      console.error('âŒ DeepLab ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—:', error);
      throw error;
    }
  }

  /**
   * Mask R-CNN ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
   */
  private async loadMaskRCNNModel(): Promise<void> {
    try {
      console.log('ğŸ“¥ Mask R-CNN ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...');
      
      const model = await this.createMaskRCNNModel();
      this.segmentationModels.set('maskrcnn', model);
      
      console.log('âœ… Mask R-CNN ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†');
    } catch (error) {
      console.error('âŒ Mask R-CNN ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—:', error);
      throw error;
    }
  }

  /**
   * U-Net ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
   */
  private async loadUNetModel(): Promise<void> {
    try {
      console.log('ğŸ“¥ U-Net ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...');
      
      const model = await this.createUNetModel();
      this.segmentationModels.set('unet', model);
      
      console.log('âœ… U-Net ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†');
    } catch (error) {
      console.error('âŒ U-Net ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—:', error);
      throw error;
    }
  }

  /**
   * è¤‡æ•°é ˜åŸŸåˆ‡ã‚Šå‡ºã—å®Ÿè¡Œ
   */
  public async extractMultipleRegions(
    imageUri: string,
    config: Partial<RegionExtractionConfig> = {}
  ): Promise<MultiRegionOutput> {
    if (!this.isInitialized) {
      throw new Error('è¤‡æ•°é ˜åŸŸåˆ‡ã‚Šå‡ºã—ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“');
    }

    const startTime = Date.now();
    const finalConfig = { ...this.defaultConfig, ...config };

    try {
      console.log('ğŸ” è¤‡æ•°é ˜åŸŸåˆ‡ã‚Šå‡ºã—é–‹å§‹...');

      // 1. ç‰©ä½“æ¤œå‡ºå®Ÿè¡Œ
      const detectionResult = await this.objectDetectionService.detectWithEnsemble(imageUri);
      console.log(`ğŸ“Š ${detectionResult.totalObjects}å€‹ã®ç‰©ä½“ã‚’æ¤œå‡º`);

      // 2. ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
      const segmentationMasks = await this.performSegmentation(imageUri, detectionResult.detections);
      console.log(`ğŸ­ ${segmentationMasks.length}å€‹ã®ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆ`);

      // 3. é ˜åŸŸå“è³ªè©•ä¾¡
      const qualifiedRegions = this.filterRegionsByQuality(segmentationMasks, finalConfig);
      console.log(`âœ… ${qualifiedRegions.length}å€‹ã®é«˜å“è³ªé ˜åŸŸã‚’é¸æŠ`);

      // 4. é ˜åŸŸåˆ‡ã‚Šå‡ºã—å®Ÿè¡Œ
      const extractedRegions = await this.extractRegions(
        imageUri,
        qualifiedRegions,
        detectionResult.detections,
        finalConfig
      );

      const totalProcessingTime = Date.now() - startTime;
      const successfulExtractions = extractedRegions.length;
      const failedExtractions = qualifiedRegions.length - successfulExtractions;

      console.log(`ğŸ‰ è¤‡æ•°é ˜åŸŸåˆ‡ã‚Šå‡ºã—å®Œäº†: ${successfulExtractions}å€‹æˆåŠŸ (${totalProcessingTime}ms)`);

      return {
        regions: extractedRegions,
        totalRegions: extractedRegions.length,
        originalImageSize: detectionResult.imageSize,
        processingMetrics: {
          totalProcessingTime,
          averageQualityScore: this.calculateAverageQuality(extractedRegions),
          successfulExtractions,
          failedExtractions
        },
        metadata: {
          algorithm: 'multi-region-extraction',
          version: '1.0.0',
          timestamp: new Date()
        }
      };

    } catch (error) {
      console.error('âŒ è¤‡æ•°é ˜åŸŸåˆ‡ã‚Šå‡ºã—ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  /**
   * ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
   */
  public async performInstanceSegmentation(imageUri: string): Promise<SegmentationMask[]> {
    try {
      console.log('ğŸ­ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹...');

      // Mask R-CNNã§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
      const maskRCNNResult = await this.runMaskRCNN(imageUri);
      
      // çµæœå¾Œå‡¦ç†
      const masks = await this.postProcessSegmentation(maskRCNNResult);
      
      console.log(`âœ… ${masks.length}å€‹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆ`);
      return masks;

    } catch (error) {
      console.error('âŒ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  /**
   * ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
   */
  public async performSemanticSegmentation(imageUri: string): Promise<number[][]> {
    try {
      console.log('ğŸ¨ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹...');

      // DeepLab v3+ã§ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
      const segmentationMap = await this.runDeepLab(imageUri);
      
      console.log('âœ… ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†');
      return segmentationMap;

    } catch (error) {
      console.error('âŒ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  /**
   * è‡ªå‹•èƒŒæ™¯é™¤å»
   */
  public async removeBackground(
    imageUri: string,
    targetObject?: string
  ): Promise<string> {
    try {
      console.log('ğŸ¨ èƒŒæ™¯é™¤å»é–‹å§‹...');

      // U-Netã§å‰æ™¯/èƒŒæ™¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
      const foregroundMask = await this.generateForegroundMask(imageUri, targetObject);
      
      // èƒŒæ™¯é™¤å»é©ç”¨
      const processedImage = await this.applyBackgroundRemoval(imageUri, foregroundMask);
      
      console.log('âœ… èƒŒæ™¯é™¤å»å®Œäº†');
      return processedImage;

    } catch (error) {
      console.error('âŒ èƒŒæ™¯é™¤å»ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  /**
   * ã‚¹ãƒãƒ¼ãƒˆã‚¯ãƒ­ãƒƒãƒ”ãƒ³ã‚°
   */
  public async smartCrop(
    imageUri: string,
    targetSize: { width: number; height: number },
    focusObjects?: string[]
  ): Promise<string> {
    try {
      console.log('âœ‚ï¸ ã‚¹ãƒãƒ¼ãƒˆã‚¯ãƒ­ãƒƒãƒ”ãƒ³ã‚°é–‹å§‹...');

      // é‡è¦é ˜åŸŸæ¤œå‡º
      const importantRegions = await this.detectImportantRegions(imageUri, focusObjects);
      
      // æœ€é©ã‚¯ãƒ­ãƒƒãƒ—é ˜åŸŸè¨ˆç®—
      const cropArea = this.calculateOptimalCropArea(importantRegions, targetSize);
      
      // ã‚¯ãƒ­ãƒƒãƒ”ãƒ³ã‚°å®Ÿè¡Œ
      const croppedImage = await this.applyCropping(imageUri, cropArea, targetSize);
      
      console.log('âœ… ã‚¹ãƒãƒ¼ãƒˆã‚¯ãƒ­ãƒƒãƒ”ãƒ³ã‚°å®Œäº†');
      return croppedImage;

    } catch (error) {
      console.error('âŒ ã‚¹ãƒãƒ¼ãƒˆã‚¯ãƒ­ãƒƒãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  /**
   * ãƒãƒƒãƒé ˜åŸŸå‡¦ç†
   */
  public async batchExtractRegions(
    imageUris: string[],
    config: Partial<RegionExtractionConfig> = {}
  ): Promise<MultiRegionOutput[]> {
    try {
      console.log(`ğŸ“¦ ãƒãƒƒãƒå‡¦ç†é–‹å§‹: ${imageUris.length}æšã®ç”»åƒ`);

      const results = await Promise.all(
        imageUris.map(uri => this.extractMultipleRegions(uri, config))
      );

      console.log('âœ… ãƒãƒƒãƒå‡¦ç†å®Œäº†');
      return results;

    } catch (error) {
      console.error('âŒ ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  // ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ¡ã‚½ãƒƒãƒ‰ç¾¤

  private async createDeepLabModel(): Promise<tf.LayersModel> {
    // DeepLab v3+ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    const input = tf.input({ shape: [513, 513, 3] });
    
    // ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆXception backboneï¼‰
    let encoder = this.createXceptionBackbone(input);
    
    // ASPP (Atrous Spatial Pyramid Pooling)
    const aspp = this.createASPPModule(encoder);
    
    // ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼
    const decoder = this.createDeepLabDecoder(aspp, input);
    
    // å‡ºåŠ›å±¤
    const output = tf.layers.conv2d({
      filters: 21, // PASCAL VOC classes
      kernelSize: 1,
      activation: 'softmax'
    }).apply(decoder) as tf.SymbolicTensor;
    
    const model = tf.model({ inputs: input, outputs: output });
    
    model.compile({
      optimizer: tf.train.adam(0.0001),
      loss: 'categoricalCrossentropy',
      metrics: ['accuracy']
    });

    return model;
  }

  private async createMaskRCNNModel(): Promise<tf.LayersModel> {
    // Mask R-CNN ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    const input = tf.input({ shape: [800, 800, 3] });
    
    // ResNet-101 FPN backbone
    const backbone = this.createResNetFPN(input);
    
    // RPN (Region Proposal Network)
    const rpn = this.createRPN(backbone);
    
    // ROI Align
    const roiFeatures = this.createROIAlign(backbone, rpn);
    
    // ãƒã‚¹ã‚¯ãƒ˜ãƒƒãƒ‰
    const masks = tf.layers.conv2d({
      filters: 256,
      kernelSize: 3,
      padding: 'same',
      activation: 'relu'
    }).apply(roiFeatures) as tf.SymbolicTensor;
    
    const maskOutput = tf.layers.conv2d({
      filters: 80, // COCO classes
      kernelSize: 1,
      activation: 'sigmoid'
    }).apply(masks) as tf.SymbolicTensor;
    
    const model = tf.model({ inputs: input, outputs: maskOutput });
    
    model.compile({
      optimizer: tf.train.adam(0.001),
      loss: 'binaryCrossentropy',
      metrics: ['accuracy']
    });

    return model;
  }

  private async createUNetModel(): Promise<tf.LayersModel> {
    // U-Net ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    const input = tf.input({ shape: [256, 256, 3] });
    
    // ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
    const encoder1 = this.createUNetBlock(input, 64);
    const encoder2 = this.createUNetBlock(encoder1, 128, true);
    const encoder3 = this.createUNetBlock(encoder2, 256, true);
    const encoder4 = this.createUNetBlock(encoder3, 512, true);
    
    // ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
    const bottleneck = this.createUNetBlock(encoder4, 1024, true);
    
    // ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
    const decoder4 = this.createUNetUpBlock(bottleneck, encoder4, 512);
    const decoder3 = this.createUNetUpBlock(decoder4, encoder3, 256);
    const decoder2 = this.createUNetUpBlock(decoder3, encoder2, 128);
    const decoder1 = this.createUNetUpBlock(decoder2, encoder1, 64);
    
    // å‡ºåŠ›å±¤
    const output = tf.layers.conv2d({
      filters: 1,
      kernelSize: 1,
      activation: 'sigmoid'
    }).apply(decoder1) as tf.SymbolicTensor;
    
    const model = tf.model({ inputs: input, outputs: output });
    
    model.compile({
      optimizer: tf.train.adam(0.001),
      loss: 'binaryCrossentropy',
      metrics: ['accuracy']
    });

    return model;
  }

  // ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤

  private async performSegmentation(
    imageUri: string,
    detections: DetectionResult[]
  ): Promise<SegmentationMask[]> {
    const masks: SegmentationMask[] = [];

    for (const detection of detections) {
      try {
        // å„æ¤œå‡ºé ˜åŸŸã«å¯¾ã—ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        const mask = await this.generateSegmentationMask(imageUri, detection);
        masks.push(mask);
      } catch (error) {
        console.warn(`âš ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: ${detection.class}`, error);
      }
    }

    return masks;
  }

  private async generateSegmentationMask(
    imageUri: string,
    detection: DetectionResult
  ): Promise<SegmentationMask> {
    // ãƒ¢ãƒƒã‚¯ãƒã‚¹ã‚¯ç”Ÿæˆï¼ˆå®Ÿè£…ã§ã¯å®Ÿéš›ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ï¼‰
    const { bbox } = detection;
    const mask: number[][] = [];
    
    for (let y = 0; y < bbox.height; y++) {
      const row: number[] = [];
      for (let x = 0; x < bbox.width; x++) {
        // æ¥•å††å½¢ã®ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆ
        const centerX = bbox.width / 2;
        const centerY = bbox.height / 2;
        const radiusX = bbox.width * 0.4;
        const radiusY = bbox.height * 0.4;
        
        const distance = Math.sqrt(
          Math.pow((x - centerX) / radiusX, 2) + 
          Math.pow((y - centerY) / radiusY, 2)
        );
        
        row.push(distance <= 1 ? 1 : 0);
      }
      mask.push(row);
    }

    return {
      mask,
      boundingBox: bbox,
      area: bbox.width * bbox.height,
      confidence: detection.confidence
    };
  }

  private filterRegionsByQuality(
    masks: SegmentationMask[],
    config: RegionExtractionConfig
  ): SegmentationMask[] {
    return masks
      .filter(mask => {
        // æœ€å°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        const minDimension = Math.min(mask.boundingBox.width, mask.boundingBox.height);
        if (minDimension < config.minRegionSize) return false;
        
        // å“è³ªã‚¹ã‚³ã‚¢ãƒã‚§ãƒƒã‚¯
        if (mask.confidence < config.qualityThreshold) return false;
        
        return true;
      })
      .sort((a, b) => b.confidence - a.confidence)
      .slice(0, config.maxRegions);
  }

  private async extractRegions(
    imageUri: string,
    masks: SegmentationMask[],
    detections: DetectionResult[],
    config: RegionExtractionConfig
  ): Promise<ExtractedRegion[]> {
    const regions: ExtractedRegion[] = [];

    for (let i = 0; i < masks.length; i++) {
      try {
        const mask = masks[i];
        const detection = detections[i];
        
        // é ˜åŸŸåˆ‡ã‚Šå‡ºã—å®Ÿè¡Œ
        const extractedImage = await this.cropRegion(imageUri, mask, config);
        
        regions.push({
          id: `region_${i}_${Date.now()}`,
          imageData: extractedImage,
          originalBbox: mask.boundingBox,
          croppedSize: config.outputSize || { width: 224, height: 224 },
          segmentationMask: mask,
          objectClass: detection?.class || 'unknown',
          confidence: mask.confidence,
          extractionMetadata: {
            algorithm: 'multi-region-extraction',
            processingTime: Date.now(),
            qualityScore: this.calculateRegionQuality(mask),
            timestamp: new Date()
          }
        });

      } catch (error) {
        console.warn(`âš ï¸ é ˜åŸŸåˆ‡ã‚Šå‡ºã—å¤±æ•—: ${i}`, error);
      }
    }

    return regions;
  }

  private async cropRegion(
    imageUri: string,
    mask: SegmentationMask,
    config: RegionExtractionConfig
  ): Promise<string> {
    // å®Ÿè£…ã§ã¯å®Ÿéš›ã®ç”»åƒåˆ‡ã‚Šå‡ºã—å‡¦ç†ã‚’è¡Œã†
    // ã“ã“ã§ã¯ãƒ¢ãƒƒã‚¯Base64ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
    return 'data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAABAAEDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAv/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAX/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwCdABmX/9k=';
  }

  private calculateRegionQuality(mask: SegmentationMask): number {
    // é ˜åŸŸå“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
    const area = mask.area;
    const bbox = mask.boundingBox;
    const aspectRatio = bbox.width / bbox.height;
    
    // ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚¹ã‚³ã‚¢ï¼ˆæ­£æ–¹å½¢ã«è¿‘ã„ã»ã©é«˜ã‚¹ã‚³ã‚¢ï¼‰
    const aspectScore = 1 - Math.abs(1 - aspectRatio) / 2;
    
    // ã‚µã‚¤ã‚ºã‚¹ã‚³ã‚¢ï¼ˆé©åˆ‡ãªã‚µã‚¤ã‚ºã»ã©é«˜ã‚¹ã‚³ã‚¢ï¼‰
    const sizeScore = Math.min(area / 10000, 1);
    
    // ä¿¡é ¼åº¦
    const confidenceScore = mask.confidence;
    
    return (aspectScore + sizeScore + confidenceScore) / 3;
  }

  private calculateAverageQuality(regions: ExtractedRegion[]): number {
    if (regions.length === 0) return 0;
    
    const sum = regions.reduce((acc, region) => acc + region.extractionMetadata.qualityScore, 0);
    return sum / regions.length;
  }

  // ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰

  private createXceptionBackbone(input: tf.SymbolicTensor): tf.SymbolicTensor {
    let x = input;
    
    // Entry flow
    x = tf.layers.conv2d({ filters: 32, kernelSize: 3, strides: 2, padding: 'same' }).apply(x) as tf.SymbolicTensor;
    x = tf.layers.batchNormalization().apply(x) as tf.SymbolicTensor;
    x = tf.layers.activation({ activation: 'relu' }).apply(x) as tf.SymbolicTensor;
    
    // Middle flow (repeated)
    for (let i = 0; i < 8; i++) {
      x = this.createXceptionBlock(x, 728);
    }
    
    return x;
  }

  private createXceptionBlock(input: tf.SymbolicTensor, filters: number): tf.SymbolicTensor {
    let x = tf.layers.depthwiseConv2d({ kernelSize: 3, padding: 'same' }).apply(input) as tf.SymbolicTensor;
    x = tf.layers.batchNormalization().apply(x) as tf.SymbolicTensor;
    x = tf.layers.activation({ activation: 'relu' }).apply(x) as tf.SymbolicTensor;
    
    x = tf.layers.conv2d({ filters, kernelSize: 1 }).apply(x) as tf.SymbolicTensor;
    x = tf.layers.batchNormalization().apply(x) as tf.SymbolicTensor;
    
    return tf.layers.add().apply([input, x]) as tf.SymbolicTensor;
  }

  private createASPPModule(input: tf.SymbolicTensor): tf.SymbolicTensor {
    // Atrous rates
    const rates = [1, 6, 12, 18];
    const branches: tf.SymbolicTensor[] = [];
    
    for (const rate of rates) {
      const branch = tf.layers.conv2d({
        filters: 256,
        kernelSize: 3,
        padding: 'same',
        dilationRate: rate
      }).apply(input) as tf.SymbolicTensor;
      branches.push(branch);
    }
    
    // Global average pooling branch
    const globalPool = tf.layers.globalAveragePooling2d({}).apply(input) as tf.SymbolicTensor;
    const globalBranch = tf.layers.conv2d({ filters: 256, kernelSize: 1 }).apply(globalPool) as tf.SymbolicTensor;
    branches.push(globalBranch);
    
    return tf.layers.concatenate().apply(branches) as tf.SymbolicTensor;
  }

  private createDeepLabDecoder(aspp: tf.SymbolicTensor, input: tf.SymbolicTensor): tf.SymbolicTensor {
    // ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    let x = tf.layers.upSampling2d({ size: [4, 4] }).apply(aspp) as tf.SymbolicTensor;
    
    // ä½ãƒ¬ãƒ™ãƒ«ç‰¹å¾´ã¨ã®èåˆ
    const lowLevel = tf.layers.conv2d({ filters: 48, kernelSize: 1 }).apply(input) as tf.SymbolicTensor;
    x = tf.layers.concatenate().apply([x, lowLevel]) as tf.SymbolicTensor;
    
    // ç²¾ç·»åŒ–
    x = tf.layers.conv2d({ filters: 256, kernelSize: 3, padding: 'same' }).apply(x) as tf.SymbolicTensor;
    x = tf.layers.upSampling2d({ size: [4, 4] }).apply(x) as tf.SymbolicTensor;
    
    return x;
  }

  private createResNetFPN(input: tf.SymbolicTensor): tf.SymbolicTensor {
    // ç°¡ç•¥åŒ–ã•ã‚ŒãŸResNet FPNå®Ÿè£…
    let x = input;
    
    // Stage 1-4
    for (let stage = 0; stage < 4; stage++) {
      const filters = 64 * Math.pow(2, stage);
      for (let block = 0; block < 3; block++) {
        x = this.createResNetBlock(x, filters);
      }
    }
    
    return x;
  }

  private createResNetBlock(input: tf.SymbolicTensor, filters: number): tf.SymbolicTensor {
    let x = tf.layers.conv2d({ filters, kernelSize: 3, padding: 'same' }).apply(input) as tf.SymbolicTensor;
    x = tf.layers.batchNormalization().apply(x) as tf.SymbolicTensor;
    x = tf.layers.activation({ activation: 'relu' }).apply(x) as tf.SymbolicTensor;
    
    return tf.layers.add().apply([input, x]) as tf.SymbolicTensor;
  }

  private createRPN(backbone: tf.SymbolicTensor): tf.SymbolicTensor {
    // Region Proposal Network
    let x = tf.layers.conv2d({ filters: 512, kernelSize: 3, padding: 'same' }).apply(backbone) as tf.SymbolicTensor;
    
    // Classification
    const cls = tf.layers.conv2d({ filters: 3, kernelSize: 1 }).apply(x) as tf.SymbolicTensor;
    
    // Regression
    const reg = tf.layers.conv2d({ filters: 12, kernelSize: 1 }).apply(x) as tf.SymbolicTensor;
    
    return tf.layers.concatenate().apply([cls, reg]) as tf.SymbolicTensor;
  }

  private createROIAlign(backbone: tf.SymbolicTensor, rpn: tf.SymbolicTensor): tf.SymbolicTensor {
    // ç°¡ç•¥åŒ–ã•ã‚ŒãŸROI Alignå®Ÿè£…
    return tf.layers.averagePooling2d({ poolSize: 7, strides: 7 }).apply(backbone) as tf.SymbolicTensor;
  }

  private createUNetBlock(input: tf.SymbolicTensor, filters: number, pool: boolean = false): tf.SymbolicTensor {
    let x = tf.layers.conv2d({ filters, kernelSize: 3, padding: 'same', activation: 'relu' }).apply(input) as tf.SymbolicTensor;
    x = tf.layers.conv2d({ filters, kernelSize: 3, padding: 'same', activation: 'relu' }).apply(x) as tf.SymbolicTensor;
    
    if (pool) {
      x = tf.layers.maxPooling2d({ poolSize: 2, strides: 2 }).apply(x) as tf.SymbolicTensor;
    }
    
    return x;
  }

  private createUNetUpBlock(input: tf.SymbolicTensor, skip: tf.SymbolicTensor, filters: number): tf.SymbolicTensor {
    let x = tf.layers.upSampling2d({ size: [2, 2] }).apply(input) as tf.SymbolicTensor;
    x = tf.layers.concatenate().apply([x, skip]) as tf.SymbolicTensor;
    x = tf.layers.conv2d({ filters, kernelSize: 3, padding: 'same', activation: 'relu' }).apply(x) as tf.SymbolicTensor;
    x = tf.layers.conv2d({ filters, kernelSize: 3, padding: 'same', activation: 'relu' }).apply(x) as tf.SymbolicTensor;
    
    return x;
  }

  // æ¨è«–å®Ÿè¡Œãƒ¡ã‚½ãƒƒãƒ‰ç¾¤

  private async runMaskRCNN(imageUri: string): Promise<tf.Tensor> {
    const model = this.segmentationModels.get('maskrcnn');
    if (!model) {
      throw new Error('Mask R-CNN ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
    }
    
    // å®Ÿè£…ã§ã¯å®Ÿéš›ã®å‰å‡¦ç†ã¨æ¨è«–ã‚’è¡Œã†
    const input = tf.zeros([1, 800, 800, 3]);
    return model.predict(input) as tf.Tensor;
  }

  private async runDeepLab(imageUri: string): Promise<number[][]> {
    const model = this.segmentationModels.get('deeplab');
    if (!model) {
      throw new Error('DeepLab ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
    }
    
    // ãƒ¢ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒƒãƒ—ç”Ÿæˆ
    const height = 513;
    const width = 513;
    const segMap: number[][] = [];
    
    for (let y = 0; y < height; y++) {
      const row: number[] = [];
      for (let x = 0; x < width; x++) {
        row.push(Math.floor(Math.random() * 21)); // 21ã‚¯ãƒ©ã‚¹
      }
      segMap.push(row);
    }
    
    return segMap;
  }

  private async postProcessSegmentation(predictions: tf.Tensor): Promise<SegmentationMask[]> {
    const masks: SegmentationMask[] = [];
    
    // ãƒ¢ãƒƒã‚¯å¾Œå‡¦ç†
    const numMasks = Math.floor(Math.random() * 5) + 1;
    
    for (let i = 0; i < numMasks; i++) {
      masks.push({
        mask: this.generateMockMask(100, 100),
        boundingBox: {
          x: Math.random() * 300,
          y: Math.random() * 300,
          width: Math.random() * 100 + 50,
          height: Math.random() * 100 + 50
        },
        area: (Math.random() * 100 + 50) * (Math.random() * 100 + 50),
        confidence: Math.random() * 0.4 + 0.6
      });
    }
    
    return masks;
  }

  private generateMockMask(width: number, height: number): number[][] {
    const mask: number[][] = [];
    
    for (let y = 0; y < height; y++) {
      const row: number[] = [];
      for (let x = 0; x < width; x++) {
        const centerX = width / 2;
        const centerY = height / 2;
        const distance = Math.sqrt(Math.pow(x - centerX, 2) + Math.pow(y - centerY, 2));
        const radius = Math.min(width, height) / 3;
        
        row.push(distance <= radius ? 1 : 0);
      }
      mask.push(row);
    }
    
    return mask;
  }

  private async generateForegroundMask(imageUri: string, targetObject?: string): Promise<number[][]> {
    // U-Netã§å‰æ™¯ãƒã‚¹ã‚¯ç”Ÿæˆ
    const model = this.segmentationModels.get('unet');
    if (!model) {
      throw new Error('U-Net ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
    }
    
    // ãƒ¢ãƒƒã‚¯å‰æ™¯ãƒã‚¹ã‚¯ç”Ÿæˆ
    return this.generateMockMask(256, 256);
  }

  private async applyBackgroundRemoval(imageUri: string, mask: number[][]): Promise<string> {
    // èƒŒæ™¯é™¤å»é©ç”¨
    // å®Ÿè£…ã§ã¯å®Ÿéš›ã®ç”»åƒå‡¦ç†ã‚’è¡Œã†
    return 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg==';
  }

  private async detectImportantRegions(imageUri: string, focusObjects?: string[]): Promise<any[]> {
    // é‡è¦é ˜åŸŸæ¤œå‡º
    return [];
  }

  private calculateOptimalCropArea(regions: any[], targetSize: { width: number; height: number }): any {
    // æœ€é©ã‚¯ãƒ­ãƒƒãƒ—é ˜åŸŸè¨ˆç®—
    return {
      x: 0,
      y: 0,
      width: targetSize.width,
      height: targetSize.height
    };
  }

  private async applyCropping(imageUri: string, cropArea: any, targetSize: { width: number; height: number }): Promise<string> {
    // ã‚¯ãƒ­ãƒƒãƒ”ãƒ³ã‚°é©ç”¨
    return 'data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAABAAEDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAv/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAX/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwCdABmX/9k=';
  }

  /**
   * ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
   */
  public dispose(): void {
    for (const [name, model] of this.segmentationModels) {
      model.dispose();
      console.log(`ğŸ—‘ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ« ${name} ã‚’è§£æ”¾ã—ã¾ã—ãŸ`);
    }
    this.segmentationModels.clear();
    this.isInitialized = false;
  }
}
